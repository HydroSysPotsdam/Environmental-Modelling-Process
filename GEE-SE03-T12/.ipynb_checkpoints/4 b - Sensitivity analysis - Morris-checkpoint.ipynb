{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58baaf00-a910-45da-90ab-73ba980d7024",
   "metadata": {},
   "source": [
    "![](./figures/Logo.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae7cf3-5f1c-4c4b-ac38-adaeb9ade587",
   "metadata": {},
   "source": [
    "## In this part of the tutorial, you will\n",
    "* use the Morris sensitivity analysis method\n",
    "* analyse the convergence of sensitivities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d3773-15c0-4c85-aad3-9c9d711efbc0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a063a-fe29-47bf-9d61-074dbb703840",
   "metadata": {},
   "source": [
    "# 4 b - Sensitivity analysis using the Morris method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef46d68-95a8-438b-809d-5f91bf796ae1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a666a-9e3c-4186-ad4d-4c92b0663bc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1 About the Morris method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a93d0-0606-4fd7-b549-40db232a9dd3",
   "metadata": {},
   "source": [
    "The Morris method is a **computationally efficient** and well-established global sensitivity analysis (GSA). \n",
    "It starts with generating a set of random points in a defined parameter space, made up by the lower and upper bounds of each parameter. \n",
    "For these baseline points, the elementary effects (EEs) of each parameter are received by **perturbing each parameter by a defined distance $\\Delta$** and **calculating the finite difference in the output**. \n",
    "\n",
    "This output is usually the result of some objective function (e.g., NSE).\n",
    "\n",
    "The **total effect of a parameter** is calculated as the **mean of the absolute EEs** over the baseline points. \n",
    "A higher total effect means higher sensitivity towards the respective parameter. \n",
    "\n",
    "A high **standard deviation of the total effect** indicates **high interaction between that parameter and other parameters**.\n",
    "\n",
    "Owing to the low number of samples, the results can differ between individual runs of the Morris method. Multiple runs of the Morris method with new EEs, i.e. [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)), can be used to create confidence limits for parameter sensitivity.\n",
    "\n",
    "For further information on the Morris method, check out [this publication](https://doi.org/10.5281/zenodo.6110623 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5176e1-0425-4706-a979-0d41cafbd46a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2 Using the Morris method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f30ef2-f15b-4b4c-937d-ae9019ece355",
   "metadata": {},
   "source": [
    "In this notebook, you will apply the Morris method to screen and potentially rank HBV parameter sensitivity. \n",
    "In other words, you will assess, which parameters are important for the model output and which we might want to omit for following investigations of the studied catchment.\n",
    "\n",
    "You will see that some parameters stand out while others are clustered, having similar standard deviation and mean of the EEs. We will use bootstrapping to get confidence limits for each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbdfa1-b8a1-47e4-afa8-1b8ccad2ee72",
   "metadata": {},
   "source": [
    "### 2.1 Preparations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947dc5e-c974-4e2a-9a6e-8bfd9b9f004e",
   "metadata": {},
   "source": [
    "**Import python modules, define functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bfd5f8-4284-48b7-88f1-56a8c6e83b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "import EET # module to perform the EET\n",
    "import plot_functions as pf # module to visualize the results\n",
    "from sampling import OAT_sampling # functions to perform the input sampling\n",
    "from util import aggregate_boot # function to aggregate the bootstrap results\n",
    "import HBV\n",
    "# Supress warnings from numba\n",
    "import logging\n",
    "logger = logging.getLogger(\"numba\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "from ipywidgets import interact\n",
    "\n",
    "def calc_nse(obs, sim):\n",
    "    # Nash-Sutcliffe efficiency (NSE)\n",
    "    # range: negative infinity to 1\n",
    "    # optimal value: 1\n",
    "    r_nse = np.corrcoef(obs, sim)[0][1] \n",
    "    alpha_nse = np.divide(np.std(sim), np.std(obs))\n",
    "    beta_nse = np.divide(np.subtract(np.mean(sim), np.mean(obs)), np.std(obs))\n",
    "    nse = 2 * alpha_nse * r_nse - np.square(alpha_nse) - np.square(beta_nse)\n",
    "    return nse\n",
    "\n",
    "def hbv(par, precip, temp, evap):\n",
    "    # Run HBV snow routine\n",
    "    p_s, _, _ = HBV.snow_routine(par[:4], temp, precip)\n",
    "    # Run HBV runoff simulation\n",
    "    Case = 1 # for now we assume that the preferred path in the upper zone is runoff (Case = 1), it can be set to percolation (Case = 2)\n",
    "    ini = np.array([0,0,0]) # initial state\n",
    "    runoff_sim, _, _ = HBV.hbv_sim(par[4:], p_s, evap, Case, ini)\n",
    "    return runoff_sim\n",
    "\n",
    "def hbv_and_one_obj_fun(par, precip, temp, evap, runoff_obs, n_days, obj_fun):\n",
    "    runoff_sim = hbv(par, precip, temp, evap)\n",
    "    \n",
    "    errors = obj_fun(runoff_obs[n_days:], runoff_sim[n_days:])\n",
    "    return errors, runoff_sim[n_days:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c057d-9102-47aa-8766-1cd8744d3f6e",
   "metadata": {},
   "source": [
    "**Read catchment data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fec6c96-b8ed-49cf-af6b-9c457a21b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read catchment data\n",
    "catchment_name = \"Siletz River, OR, USA\"\n",
    "file_dic = {catchment_name: \"camels_14305500\"}\n",
    "df_obs = pd.read_csv(f\"data/{file_dic[catchment_name]}.csv\")\n",
    "# Make sure the date is interpreted as a datetime object -> makes temporal operations easier\n",
    "df_obs.date = pd.to_datetime(df_obs['date'], format='%Y-%m-%d')\n",
    "# Index frame by date\n",
    "df_obs.set_index('date', inplace=True)\n",
    "# Select only the columns we need\n",
    "df_obs = df_obs[[\"total_precipitation_sum\",\"potential_evaporation_sum\",\"streamflow\", \"temperature_2m_mean\"]]\n",
    "# Rename variables\n",
    "df_obs.columns = [\"P [mm/day]\", \"PET [mm/day]\", \"Q [mm/day]\", \"T [C]\"]\n",
    "# Select time frame\n",
    "start_date = '2002-10-01'\n",
    "end_date = '2005-09-30'\n",
    "df_obs = df_obs[start_date:end_date]\n",
    "# Reformat the date for plotting\n",
    "df_obs[\"Date\"] = df_obs.index.map(lambda s: s.strftime('%b-%d-%y'))\n",
    "\n",
    "# Prepare the time series intput\n",
    "P = df_obs[\"P [mm/day]\"].to_numpy()\n",
    "PET = df_obs[\"PET [mm/day]\"].to_numpy()\n",
    "T = df_obs[\"T [C]\"].to_numpy()\n",
    "Q_obs = df_obs[\"Q [mm/day]\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82bfc4-23b7-4336-a088-db52fe34a645",
   "metadata": {},
   "source": [
    "**Setup HBV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0a0990-ca5c-4492-9262-dc5d1ff1659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spinup_days = 365\n",
    "n_par_sets = 100\n",
    "rmse_threshold = 2\n",
    "bias_threshold = 1\n",
    "dic_threshold = {'rmse': rmse_threshold, 'bias': bias_threshold}\n",
    "\n",
    "# define parameter names\n",
    "parameter_names = [\"Ts\", \"CFMAX\", \"CFR\", \"CWH\", \"BETA\", \"LP\", \"FC\", \"PERC\", \"K0\", \"K1\", \"K2\", \"UZL\", \"MAXBAS\"]  \n",
    "\n",
    "n_parameters = len(parameter_names)\n",
    "\n",
    "# define marameter bounds\n",
    "xmin = [-3, 0, 0, 0, 0, 0.3, 1, 0, 0.05, 0.01, 0.005, 0, 1]\n",
    "xmax = [3, 20, 1, 0.8, 7, 1, 2000, 100, 2, 1, 0.1, 100, 6]\n",
    "\n",
    "# define distribution\n",
    "distr_fun = st.uniform # uniform distribution\n",
    "distr_par = [np.nan] * n_parameters\n",
    "for i in range(n_parameters):\n",
    "    distr_par[i] = [xmin[i], xmax[i] - xmin[i]]\n",
    "\n",
    "# define the sampling design type\n",
    "design_type = \"radial\"\n",
    "\n",
    "# define the sampling strategy\n",
    "sampling_strategy = \"lhs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48731ac5-1394-4254-9ceb-16b5ad2ee765",
   "metadata": {},
   "source": [
    "### 2.2 Applying the Morris method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc02290-0ef4-42c0-9cbb-8fdab5ae9ada",
   "metadata": {},
   "source": [
    "**Run the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e686f0e4-d69d-4ba1-80f4-34dde864ce65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e681df917244332a137b778492421b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='n_EEs', min=10, step=10), Output()), _dom_classes=('widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(n_EEs = (10, 100, 10))    \n",
    "def conf_bounds_function(n_EEs = 10): # number of model runs = n_EEs * (n_parameters + 1); due to One-At-the-Time sampling\n",
    "    parameter_sets = OAT_sampling(n_EEs, n_parameters, distr_fun, distr_par, sampling_strategy, design_type) \n",
    "    # note: parameter_sets.shape = (r * (n_parameters + 1), n_parameters)\n",
    "    \n",
    "    print(f\"Number of model runs = {n_EEs} * ({n_parameters} + 1) = {parameter_sets.shape[0]}. This may take a while.\\n\") \n",
    "    errors = np.nan * np.ones(parameter_sets.shape[0]) \n",
    "    for i, parameter_set in enumerate(parameter_sets):\n",
    "        errors[i], _ = hbv_and_one_obj_fun(parameter_set, P, T, PET, Q_obs, n_spinup_days, calc_nse) \n",
    "    \n",
    "    # Computation of the elementary effects (EEs)\n",
    "    mi, sigma, _ = EET.EET_indices(n_EEs, xmin, xmax, parameter_sets, errors, design_type)\n",
    "    # mi (mean of the elementary effects) and \n",
    "    # sigma (standard deviation of the elementary effects) have shape (n_boot, n_parameters)\n",
    "    \n",
    "    # Plot results in the plane (mean(EE), std(EE)):\n",
    "    EET.EET_plot(mi, sigma, parameter_names)\n",
    "\n",
    "    # Print result as a table\n",
    "    df_res = pd.DataFrame(np.array([parameter_names, mi, sigma]).T, \n",
    "                      columns=[\"Parameters\", \"Mean of EEs (x-axis)\", \"Standard deviation of EEs (y-axis)\"])\n",
    "    df_res[\"Mean of EEs (x-axis)\"] = df_res[\"Mean of EEs (x-axis)\"].astype(float).round(4)\n",
    "    df_res[\"Standard deviation of EEs (y-axis)\"] = df_res[\"Standard deviation of EEs (y-axis)\"].astype(float).round(4)\n",
    "    print(\"Results:\")\n",
    "    print(df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e93673-ec1c-448e-8b16-24785b6e5699",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9785bdc-272c-4f32-9058-0b39cbd6b611",
   "metadata": {},
   "source": [
    "### <div class=\"blue\"><span style=\"color:blue\">Exercise section</span></div>\n",
    "### Exercise 1\n",
    "\n",
    "(a) Which parameters can you ignore? What can you say about the remaining parameters?\n",
    "\n",
    "* Answer\n",
    "\n",
    "(b) Increase the value of n_EEs using the slider above. Why do the plotted results change?\n",
    "\n",
    "* Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260f865-a214-407a-b61a-891677cfe4e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d198d3-c0e2-4afc-aa1c-177591648449",
   "metadata": {},
   "source": [
    "**Use bootstrapping to derive confidence bounds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b5394d-ae3f-4b2c-803d-85a6bd8527d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e768c0fec85400a8a69134969f6ac7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='n_bootstrap', min=10, step=10), IntSlider(value=10, desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(n_bootstrap = (10, 100, 10), n_EEs = (10, 100, 10))    \n",
    "def conf_bounds_function(n_bootstrap = 10, n_EEs = 10):\n",
    "    parameter_sets = OAT_sampling(n_EEs, n_parameters, distr_fun, distr_par, sampling_strategy, design_type) \n",
    "    print(f\"Number of model runs = {n_EEs} * ({n_parameters} + 1) = {parameter_sets.shape[0]}. This may take a while.\\n\") \n",
    "    errors = np.nan * np.ones(parameter_sets.shape[0]) # note: parameter_sets.shape = (r * (n_parameters + 1), n_parameters)\n",
    "    for i, parameter_set in enumerate(parameter_sets):\n",
    "        errors[i], _ = hbv_and_one_obj_fun(parameter_set, P, T, PET, Q_obs, n_spinup_days, calc_nse) \n",
    "        \n",
    "    # Compute sensitivity indices for Nboot bootstrap resamples:\n",
    "    mi, sigma, EE = EET.EET_indices(n_EEs, xmin, xmax, parameter_sets, errors, design_type, Nboot=n_bootstrap)\n",
    "    # mi (mean of the elementary effects) and \n",
    "    # sigma (standard deviation of the elementary effects) have shape (n_bootstrap, n_parameters)\n",
    "    \n",
    "    # Compute mean and confidence intervals of the sensitivity indices across the bootstrap resamples:\n",
    "    mi_m, mi_lb, mi_ub = aggregate_boot(mi) # shape (M,)\n",
    "    sigma_m, sigma_lb, sigma_ub = aggregate_boot(sigma) # shape (M,)\n",
    "    \n",
    "    df_res = pd.DataFrame(np.array([parameter_names, mi_m, sigma_m]).T, \n",
    "                      columns=[\"Parameters\", \"Mean of EEs (x-axis)\", \"Standard deviation of EEs (y-axis)\"])\n",
    "    df_res[\"Mean of EEs (x-axis)\"] = df_res[\"Mean of EEs (x-axis)\"].astype(float).round(4)\n",
    "    df_res[\"Standard deviation of EEs (y-axis)\"] = df_res[\"Standard deviation of EEs (y-axis)\"].astype(float).round(4)\n",
    "    print(\"Dots in the plot below:\")\n",
    "    print(df_res)\n",
    "\n",
    "    # Plot bootstrapping results in the plane (mean(EE),std(EE)):\n",
    "    EET.EET_plot(mi_m, sigma_m, parameter_names, mi_lb, mi_ub, sigma_lb, sigma_ub)\n",
    "    plt.show()\n",
    "\n",
    "    # Repeat computations using a decreasing number of samples so as to assess\n",
    "    # if convergence was reached within the available dataset:\n",
    "    rr = np.linspace(n_EEs/5, n_EEs, 5).astype(int) # Sample numbers at which the indices will be estimated\n",
    "    # Compute sensitivity indices for Nboot bootstrap resamples:\n",
    "    mic, sigmac = EET.EET_convergence(EE, rr, n_bootstrap) # mic and sigmac are lists in\n",
    "    # which the i-th element correspond to the sensitivity indices at the i-th sample size\n",
    "    \n",
    "    # Compute mean and confidence intervals of the sensitivity indices across the bootstrap resamples:\n",
    "    mic_m, mic_lb, mic_ub = aggregate_boot(mic)\n",
    "    sigmac_m, sigmac_lb, sigmac_ub = aggregate_boot(sigmac)\n",
    "    \n",
    "    # Plot the sensitivity measure (mean of elementary effects) as a function of the number of model evaluations:\n",
    "    plt.figure()\n",
    "    pf.plot_convergence(mic_m, rr*(n_parameters+1), mic_lb, mic_ub,\n",
    "                        X_Label='no of model evaluations', Y_Label='mean of EEs',\n",
    "                        labelinput=parameter_names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9af0b-62e4-4d4b-a8d9-80aaddb01c93",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04b8a9-0b52-4a61-81f2-da6de8153d48",
   "metadata": {},
   "source": [
    "### <div class=\"blue\"><span style=\"color:blue\">Exercise section</span></div>\n",
    "### Exercise 2\n",
    "\n",
    "(a) Why are the rectangular confidence intervals overlapping and how does that influence your interpretation about which parameter is most sensitive?\n",
    "\n",
    "* Answer\n",
    "\n",
    "(b) What parameter is most sensitive? What parameter shows the largest interactions?\n",
    "\n",
    "* Answer\n",
    "\n",
    "(c) At what point have you reached a convergence in sensitivity? Why is extending the original samples useful?\n",
    "\n",
    "* Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110fab7e-4251-446d-b6bc-df50ccf38983",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb585fc-061a-45f1-ade8-38855effe050",
   "metadata": {},
   "source": [
    "## Jupyter format settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c899f1f6-fca2-4d05-abc9-3ebd6d9e9e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.blue {background-color: #8dc9fc;}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html \n",
    "<style>.blue {background-color: #8dc9fc;}</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
