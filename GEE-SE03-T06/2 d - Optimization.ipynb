{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3f43d7c7-4661-4d39-85db-a4e41526cb73",
      "metadata": {
        "editable": true
      },
      "source": "![](./figures/Logo.PNG)"
    },
    {
      "cell_type": "markdown",
      "id": "49ae7cf3-5f1c-4c4b-ac38-adaeb9ade587",
      "metadata": {
        "editable": true
      },
      "source": "## In this part of the tutorial, you will\n* use a genetic algorithm to optimize model outputs globally\n* critically assess the optimized parameters and objective function results\n* implement and use your own objective function(s) "
    },
    {
      "cell_type": "markdown",
      "id": "f4e531e7-ddcc-470f-91cf-a3c51384da32",
      "metadata": {
        "editable": true
      },
      "source": "- - -"
    },
    {
      "cell_type": "markdown",
      "id": "1e4a063a-fe29-47bf-9d61-074dbb703840",
      "metadata": {
        "editable": true
      },
      "source": "# 2 d - Optimization"
    },
    {
      "cell_type": "markdown",
      "id": "1ceae26c-22c5-4c4f-acb8-cf4e55fdb33e",
      "metadata": {
        "editable": true
      },
      "source": "- - -"
    },
    {
      "cell_type": "markdown",
      "id": "a4baddff-ef3d-4560-bd52-4a9b56e89852",
      "metadata": {
        "editable": true
      },
      "source": "## 1 About optimization"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "533c4832-c044-4805-b8c8-4584a57de6fa",
      "metadata": {
        "editable": true
      },
      "source": "In the previous tutorials, we have relied on our own capacity to tune the input parameters of our model. In this tutorial, we will use an algorithm to do this job for us by minimizing an objective function we define. Such algorithms run a model multiple times and determine the optimal combination of input parameters by computing the objective function for each model output. "
    },
    {
      "cell_type": "markdown",
      "id": "69285bcc-a9a4-4e86-9dc1-f4be47e2e7fa",
      "metadata": {
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "source": "<div style=\"background:#e0f2fe; padding: 1%; border: 1mm solid SkyBlue\">\n    <h4><span>&#129300 </span>Your Turn I: Optimization Problems</h4>\n    <p>Discuss with your neighbour what problems may occur when model optimization purely relies on an algorithm?</p>\n</div>"
    },
    {
      "cell_type": "markdown",
      "id": "7bb4f6a2-8db1-4924-bb6b-f423735be9b4",
      "metadata": {
        "editable": true
      },
      "source": "## 2 Using global optimization"
    },
    {
      "cell_type": "markdown",
      "id": "ea0f755f-e94e-4189-affe-e54114150c7d",
      "metadata": {
        "editable": true
      },
      "source": "**Import packages**"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b214a76-ad32-4776-b819-4db5533d0552",
      "metadata": {},
      "outputs": [],
      "source": "import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdate\nimport sys\nsys.path.append('src/')\nimport HyMod\nfrom ipywidgets import interact, Dropdown, IntText, GridBox, FloatRangeSlider"
    },
    {
      "cell_type": "markdown",
      "id": "65479a01-62c6-478f-ad53-b5f80f09b940",
      "metadata": {
        "editable": true
      },
      "source": "**Defining functions**"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "85912016-2a0f-4ee1-9b3f-256de88b4caa",
      "metadata": {},
      "outputs": [],
      "source": "def bias(obs, sim):\n    \"\"\"\n    Calculates bias\n    obs :  The observed time series\n    sim :  The simulated time series\n    @returns : The bias\n    \"\"\"\n    return np.mean(obs - sim)\n\n\ndef rmse(obs, sim):\n    \"\"\"\n    Calculates root mean squared error\n    obs :  The observed time series\n    sim :  The simulated time series\n    @returns : The RMSE\n    \"\"\"\n    return np.sqrt(np.mean((obs - sim)**2))\n\ndef one_minus_nse(obs, sim):\n    \"\"\"\n    Calculates Nash Sutcliffe efficiency\n    obs :  The observed time series\n    sim :  The simulated time series\n    @returns : 1-NSE(obs, sim)\n    \"\"\"\n    return 1-(1 - (np.sum((obs - sim)**2)) / (np.sum((obs - np.mean(obs))**2)))\n\ndef hymod_func(param, precip, pet, runoff_obs, objective_fun, n_days, info=False):\n    param = np.array([param[0], param[1], param[2], 1/param[3], 1/param[4]])  # divide 1 by Rs and Rf for this HyMod implementation\n    runoff_sim, states, fluxes = HyMod.hymod_sim(param, precip, pet)\n    res = objective_fun(runoff_obs[n_days:], runoff_sim[n_days:])\n    if info:\n        print(f\"Parameters: Sm = {param[0]}, beta = {param[1]}, alfa = {param[2]}, Rs = {param[3]}, Rf = {param[4]}\")\n        print(f\"Result of objective function: {res}\")\n    return res"
    },
    {
      "cell_type": "markdown",
      "id": "e21b57d4-8893-49cc-bf0b-cb8257878bb1",
      "metadata": {
        "editable": true
      },
      "source": "**Create and display interactive menus for selecting catchment**"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b1200784-27b1-4901-bafc-453f0a709536",
      "metadata": {
        "editable": true,
        "jupyter": {
          "source_hidden": false
        },
        "source_hidden": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a3d63300e514dcfb5f05b90dad0b212",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "Dropdown(description='Catchment:', options=('Siletz River, OR, USA', 'Medina River, TX, USA', 'Trout River, BC\u2026"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": "# DO NOT ALTER! code to select the catchment\n\ncatchment_names = [\"Siletz River, OR, USA\", \"Medina River, TX, USA\", \"Trout River, BC, Canada\"]\ndropdown = Dropdown(\n    options=catchment_names,\n    value=catchment_names[0],\n    description='Catchment:',\n    disabled=False\n)\n\ndisplay(dropdown)"
    },
    {
      "cell_type": "markdown",
      "id": "802d3738-d190-420a-9431-b117e0a5d4ee",
      "metadata": {
        "editable": true
      },
      "source": "**Read catchment data and prepare model input**"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9d527fac-e269-4d49-a094-dda5b0e9611d",
      "metadata": {},
      "outputs": [],
      "source": "# Read catchment data\ncatchment_name = dropdown.value\n# Read catchment data\nfile_dic = {catchment_names[0]: \"camels_14305500\", catchment_names[1]: \"camels_08178880\", catchment_names[2]: \"hysets_10BE007\"}\ndf_obs = pd.read_csv(f\"data/{file_dic[catchment_name]}.csv\")\n# Make sure the date is interpreted as a datetime object -> makes temporal operations easier\ndf_obs.date = pd.to_datetime(df_obs['date'], format='%Y-%m-%d')\n# Select time frame\nstart_date = '2002-10-01'\nend_date = '2004-09-30'\nspinup_days = 365\n\n# Index frame by date\ndf_obs.set_index('date', inplace=True)\n# Select time frame\ndf_obs = df_obs[start_date:end_date]\n# Reformat the date for plotting\ndf_obs[\"date\"] = df_obs.index.map(lambda s: s.strftime('%b-%d-%y'))\n# Reindex\ndf_obs = df_obs.reset_index(drop=True)\n# Select snow, precip, PET, streamflow and T\ndf_obs = df_obs[[\"snow_depth_water_equivalent_mean\", \"total_precipitation_sum\",\"potential_evaporation_sum\",\"streamflow\", \"temperature_2m_mean\", \"date\"]]\n# Rename variables\ndf_obs.columns = [\"Snow [mm/day]\", \"P [mm/day]\", \"PET [mm/day]\", \"Q [mm/day]\", \"T [C]\", \"Date\"]\n\n# Prepare the data intput for both models\nP = df_obs[\"P [mm/day]\"].to_numpy()\nevap = df_obs[\"PET [mm/day]\"].to_numpy()\ntemp = df_obs[\"T [C]\"].to_numpy()\nq_obs = df_obs[\"Q [mm/day]\"].to_numpy()"
    },
    {
      "cell_type": "markdown",
      "id": "602019fa-5c63-4cae-a5e2-dfd06d5f07c5",
      "metadata": {
        "editable": true
      },
      "source": "**Using global optmization**\n\nThe code below runs as sequence of three optimization trials with a low iteration count to show potential differences between the trials.\n\nWe use the **Differential Evolution** algorithm from `scipy` for optimization tasks.\n\nDifferential Evolution is a stochastic, population-based optimization algorithm. It works by evolving a population of candidate solutions over several iterations. The key steps are:\n\n1. **Initialization**: Start with a randomly generated population of potential solutions.\n2. **Mutation**: For each candidate, generate new candidate solutions by combining existing solutions using a mutation strategy.\n3. **Crossover**: Create trial solutions by mixing mutated candidates with the current candidate.\n4. **Selection**: Evaluate the fitness of trial solutions and select the best solutions to form the next generation.\n\nThe algorithm continues evolving the population until a stopping criterion is met, such as a maximum number of iterations or convergence to a solution."
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "65ce3b1f-7933-462d-a5d6-888cb1948933",
      "metadata": {
        "editable": true,
        "jupyter": {
          "source_hidden": false
        },
        "source_hidden": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eab8eccd6a574d409873d9fc61d27559",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": "GridBox(children=(IntText(value=5, description='Iterations:'), Dropdown(description='Objective:', options=('Bi\u2026"
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "# DO NOT ALTER! code to select the number of iterations, objective function and parameters\n\nobjective_functions = {\"Bias\":bias, \"RMSE\": rmse, \"1-NSE\": one_minus_nse, \"Your OF 1\": None, \"Your OF 2\": None}\n\ndef check_of_implemented():\n    try:\n        if dropdown_of.value in [\"Your OF 1\", \"Your OF 2\"]: \n            objective_functions[dropdown_of.value](np.array([]), np.array([]))\n    except:\n        raise NotImplementedError(\"NO WORRIES! Your objective functions seem to be not implemented yet or throws an error. Read the blue box below...\") from None\n\nmax_iter_spn = IntText(\n    value=5,\n    description=\"Iterations:\"\n)\n\ndropdown_of = Dropdown(\n    options=objective_functions.keys(),\n    value=list(objective_functions.keys())[0],\n    description='Objective:',\n    disabled=False\n)\n\nparameters = [\"Sm\", \"beta\", \"alpha\", \"Rs\", \"Rf\"]\nbounds_rng = [(0,400), (0, 2), (0, 1), (2, 200), (1, 7)] # change max bounds range\nbounds_rng = [FloatRangeSlider(value=bound, min=bound[0], max=bound[1], step=0.1, continous_update=False, readout_format=\".1f\", description=f\"{param}:\") for bound, param in zip(bounds_rng, parameters)]\n\nGridBox([max_iter_spn, dropdown_of, *bounds_rng])"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8f791fc5-a137-49f5-8c2a-ef095ffa97bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Optimizing HyMOD for Siletz River, OR, USA with Your OF 1 (iterating up to 5 times)\n\n1. Trial\n   Random intial parameters: Sm = 245.25, beta = 0.54, alfa = 0.05, Rs = 156.33, Rf = 1.8\n   Optimization results:\n     Best found parameter set: Sm = 0.0, beta = 1.99, alfa = 1.0, Rs = 200.0, Rf = 1.152\n     (this is based on the best found result for Your OF 1: 1.748)\n\n2. Trial\n   Random intial parameters: Sm = 394.2, beta = 1.49, alfa = 0.82, Rs = 86.03, Rf = 7.0\n   Optimization results:\n     Best found parameter set: Sm = 0.0, beta = 1.345, alfa = 1.0, Rs = 111.111, Rf = 1.152\n     (this is based on the best found result for Your OF 1: 1.748)\n\n3. Trial\n   Random intial parameters: Sm = 264.61, beta = 1.92, alfa = 0.41, Rs = 156.96, Rf = 6.95\n   Optimization results:\n     Best found parameter set: Sm = 0.0, beta = 0.937, alfa = 1.0, Rs = 166.667, Rf = 1.153\n     (this is based on the best found result for Your OF 1: 1.748)\n\n"
        }
      ],
      "source": "max_iter = max_iter_spn.value\nbounds   = [bound_rng.value for bound_rng in bounds_rng]\nOF       = objective_functions[dropdown_of.value]\ncheck_of_implemented()    \n\nprint(f\"Optimizing HyMOD for {catchment_name} with {dropdown_of.value} (iterating up to {max_iter} times)\\n\")\nfor cal_round in range(1, 4):\n    # generate inital parameters randomly\n    x0 = []\n    for i in bounds:\n        low, high = i\n        x0.append(round(random.uniform(low,high), 2))\n    print(f\"{cal_round}. Trial\")\n    print(f\"   Random intial parameters: Sm = {x0[0]}, beta = {x0[1]}, alfa = {x0[2]}, Rs = {x0[3]}, Rf = {x0[4]}\")\n\n    # run the genetic algorithm to optimize the parameters\n    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html\n    # \"bounds\" are the parameter ranges\n    # \"args\" are the arguements for the evaluated function (hymod_func)\n    # \"x0\" is the initial guess or starting point for the optimization (the random parameters generated above)\n    # \"max_iter\" is the maximum number of iterations we allow the opitmization algorithm to do\n    hymod_calib = differential_evolution(hymod_func, bounds=bounds, args=(P, evap, q_obs, OF, spinup_days), x0=x0, maxiter=max_iter)\n    parameters = hymod_calib.x  # extract parameters resulting from calibration\n    \n    # divide 1 by Rs and Rf for this HyMod implementation\n    parameters = np.array([parameters[0], parameters[1], parameters[2], 1/parameters[3], 1/parameters[4]])\n    parameters = np.round(parameters, decimals=3)  # round parameters to 3 decimals\n    q_sim, states, fluxes = HyMod.hymod_sim(parameters, P, evap)  # run HyMod\n    # calculate the result of the objective function for the optimized parameters\n    obj_fun_result = OF(q_obs[spinup_days:], q_sim[spinup_days:])  \n    \n    # print calibration results\n    parameters = np.array([parameters[0], parameters[1], parameters[2], 1/parameters[3], 1/parameters[4]])\n    parameters = np.round(parameters, decimals=3)  # round parameters to 3 decimals\n    print(f\"   Optimization results:\")\n    print(f\"     Best found parameter set: Sm = {parameters[0]}, beta = {parameters[1]}, alfa = {parameters[2]}, Rs = {parameters[3]}, Rf = {parameters[4]}\")\n    print(f\"     (this is based on the best found result for {dropdown_of.value}: {round(obj_fun_result, 3)})\\n\")"
    },
    {
      "cell_type": "markdown",
      "id": "af8ad96b-a322-4fed-8421-332d60aea08a",
      "metadata": {
        "editable": true
      },
      "source": "<div style=\"background:#e0f2fe; padding: 1%; border: 1mm solid SkyBlue\">\n    <h4><span>&#129300 </span>Your Turn II: Using Global Optimization</h4>\n    <ol>\n        <li> Run the optimization for different catchments and different objective functions (change the variable \"OF\"). Compare the result of the different catchments! Where does the model perform better or worse (remember, what climatic regions the individual catchments represent)?</li>\n        <li>Why do results of the optimized objective functions change between the trials?</li>\n        <li>Why do, for the same results of the optimized objective function, some input parameters vary significantly?</li>\n        <li>Write your own implementation of an objective function of your choice</li>\n        <br>\n        <p><i>Below, we have prepared two empty functions that are not yet implemented. You may choose any of the ones we used in previous tutorials or implement completely new ones. You can then use your new function with the optimization approach.</i></p>\n    </ol>\n</div>"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "53781ead-c055-415c-814d-02a6633d674e",
      "metadata": {},
      "outputs": [],
      "source": "def yourOF1(obs, sim):\n    return bias(obs, sim) # TODO: remove and implement your own OF\n\ndef yourOF2(obs, sim):\n    raise NotImplementedError() # TODO: remove and implement your own OF\n\n# please do not remove this\nobjective_functions = {\"Bias\":bias, \"RMSE\": rmse, \"1-NSE\": one_minus_nse, \"Your OF 1\": yourOF1, \"Your OF 2\": yourOF2}"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}