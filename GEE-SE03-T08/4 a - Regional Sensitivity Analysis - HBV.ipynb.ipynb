{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987d9c60-cb44-466c-bb6c-7a3ab82911c1",
   "metadata": {
    "editable": false
   },
   "source": [
    "![](./figures/Logo.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60dace-008b-4424-8646-be6c3bc61c66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Please click the <span>&#x23E9;</span> button to run all cells before you start working on the notebook ...\n",
    "\n",
    "## In this part of the tutorial, you will\n",
    "* use regional sensitivity analysis (RSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e23e32-e513-4304-918f-6f6fb46a494e",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1dc232-d9c3-4f94-a4ac-6b334c60e7e3",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 4 a - Regional sensitivity analysis (RSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a632731-b6e3-4419-9994-9b2d12b6cd23",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8c6e2-72bc-4a91-a06a-5ed6e2dd8a67",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7aa22-2d83-43f7-bbaf-4152646f6951",
   "metadata": {
    "editable": true
   },
   "source": [
    "Regional sensitivity analysis evaluates how variations in input parameters impact the outcomes of a model. \n",
    "\n",
    "Today, we use statistical metrics to distinguish between parameter sets that produce behavioral and non-behavorial simulation output.\n",
    "We apply the same metrics to implement and assess Generalized Likelihood Uncertainty Estimation (GLUE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1227238-b432-4229-863e-f0ff3ab7df16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2 Loading Catchment Dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9643046-d1a3-4d03-a032-9c9f7cc84060",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src/')\n",
    "import HBV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from numbers import Number\n",
    "import RSA_thres as RSA           # module to perform RSA with threshold\n",
    "import plot_functions as SA_plot  # module to visualize the results\n",
    "from sampling import AAT_sampling # module to perform the input sampling\n",
    "from ipywidgets import interact, interactive_output, Dropdown, Checkbox, VBox, Layout, fixed, DatePicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6357de-fc4a-40f7-955b-19862975ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(obs, sim, spinup=365):\n",
    "    obs = obs[spinup:]\n",
    "    sim = sim[spinup:]\n",
    "    return np.sqrt(np.mean(np.square(np.subtract(obs, sim))))\n",
    "\n",
    "def abs_bias(obs, sim, spinup=365):\n",
    "    obs = obs[spinup:]\n",
    "    sim = sim[spinup:]\n",
    "    return np.mean(np.abs(sim - obs))\n",
    "\n",
    "#def nse(obs, sim, spinup=365):\n",
    "#    obs = obs[spinup:]\n",
    "#    sim = sim[spinup:]\n",
    "#    r_nse     = np.corrcoef(obs, sim)[0][1] \n",
    "#    alpha_nse = np.divide(np.std(sim), np.std(obs))\n",
    "#    beta_nse  = np.divide(np.subtract(np.mean(sim), np.mean(obs)), np.std(obs))\n",
    "#    return 2 * alpha_nse * r_nse - np.square(alpha_nse) - np.square(beta_nse)\n",
    "\n",
    "def hbv(par, precip, temp, evap):\n",
    "    # Run HBV snow routine\n",
    "    p_s, _, _ = HBV.snow_routine(par[:4], temp, precip)\n",
    "    # Run HBV runoff simulation\n",
    "    Case = 1 # for now we assume that the preferred path in the upper zone is runoff (Case = 1), it can be set to percolation (Case = 2)\n",
    "    ini = np.array([0,0,0]) # initial state\n",
    "    runoff_sim, _, _ = HBV.hbv_sim(par[4:], p_s, evap, Case, ini)\n",
    "    return runoff_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7096f45-3b7d-47e5-8877-58660afadc48",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2b8935b58b4b0ca292fb4b5b6befc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Catchment:', options=('Medina River, TX, USA', 'Siletz River, OR, USA', 'Trout River, BC…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT ALTER! code to select the catchment\n",
    "\n",
    "catchment_names = [\"Medina River, TX, USA\", \"Siletz River, OR, USA\", \"Trout River, BC, Canada\"]\n",
    "dropdown = Dropdown(\n",
    "    options=catchment_names,\n",
    "    value=catchment_names[0],\n",
    "    description='Catchment:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9a1f20-3754-4a2a-add3-9c8f04458106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read catchment data\n",
    "catchment_name = dropdown.value\n",
    "file_dic = {catchment_names[0]: \"camels_08178880\", catchment_names[1]: \"camels_14305500\", catchment_names[2]: \"hysets_10BE007\"}\n",
    "df_obs = pd.read_csv(f\"data/{file_dic[catchment_name]}.csv\")\n",
    "\n",
    "# correctly load the date and restrict analysis to one year\n",
    "df_obs.date = pd.to_datetime(df_obs['date'], format='%Y-%m-%d')\n",
    "start_date  = '2003-01-01' # the first year is used as spinup\n",
    "end_date    = '2008-12-30'\n",
    "\n",
    "# Index frame by date\n",
    "df_obs.set_index('date', inplace=True)\n",
    "# Select time frame\n",
    "df_obs = df_obs[start_date:end_date]\n",
    "# Reformat the date for plotting\n",
    "df_obs[\"date\"] = df_obs.index.map(lambda s: s.strftime('%b-%d-%y'))\n",
    "# Reindex\n",
    "df_obs = df_obs.reset_index(drop=True)\n",
    "# Select snow, precip, PET, streamflow and T\n",
    "df_obs = df_obs[[\"snow_depth_water_equivalent_mean\", \"total_precipitation_sum\",\"potential_evaporation_sum\",\"streamflow\", \"temperature_2m_mean\", \"date\"]]\n",
    "# Rename variables\n",
    "df_obs.columns = [\"Snow [mm/day]\", \"P [mm/day]\", \"PET [mm/day]\", \"Q [mm/day]\", \"T [C]\", \"Date\"]\n",
    "\n",
    "# load calibrated parameters\n",
    "params_calibrated = pd.read_csv(\"./data/calibrated_parameters - HBV.csv\")\n",
    "params_calibrated = params_calibrated[(params_calibrated.catchment_name == catchment_name) & (params_calibrated.objective_function == \"nse\")] # use only this catchment and the rmse parameters\n",
    "params_calibrated = params_calibrated.iloc[0,3:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b17c87-6ceb-49ee-ae44-35bee3c4df3c",
   "metadata": {},
   "source": [
    "## 3 Behavioral and Non-Behavioral Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478d41a3-11d6-4e53-9fad-1034f0e90227",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"Ts\", \"CFMAX\", \"CFR\", \"CWH\", \"BETA\", \"LP\", \"FC\", \"PERC\", \"K0\", \"K1\", \"K2\", \"UZL\", \"MAXBAS\"]\n",
    "lower       = np.array([-3, 0, 0, 0, 0, 0.3, 1, 0, 0.05, 0.01, 0.005, 0, 1])\n",
    "upper       = np.array([3, 20, 1, 0.8, 7, 1, 2000, 100, 2, 1, 0.1, 100, 6])\n",
    "\n",
    "#ranges = list(zip(params_calibrated, lower, upper))\n",
    "#lower  = np.array([max(low, value - 0.1*(high - low)) for value, low, high in ranges])\n",
    "#upper  = np.array([min(value + 0.1*(high - low), high) for value, low, high in ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a0fd6f-168c-4b88-8033-ee87528f6074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e50e840de2e4221b9b08760cafa6166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=300, description='N', max=500, min=50, step=10), Output()), _dom_classes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(N=(50, 500, 10))\n",
    "def sample_and_run(N=300):\n",
    "\n",
    "    # SAMPLE PARAMETER SPACE AND RUN HBV\n",
    "    np.random.seed(1234)\n",
    "\n",
    "    global samples, errors\n",
    "    \n",
    "    # take N samples using a latin-hypercube strategy for the value ranges with uniform marginal distributions\n",
    "    samples = AAT_sampling(\"lhs\", len(param_names), sp.stats.uniform, np.array([lower, upper - lower]).T.tolist(), N=N)\n",
    "    \n",
    "    # evaluate HBV for these parameters\n",
    "    errors = np.zeros((N, 2))\n",
    "    for i in range(N):\n",
    "        Q_sim = hbv(samples[i], df_obs[\"P [mm/day]\"], df_obs[\"T [C]\"], df_obs[\"PET [mm/day]\"])\n",
    "        errors[i, 0] = abs_bias(df_obs[\"Q [mm/day]\"], Q_sim) # calculate  nse for this paramter set\n",
    "        errors[i, 1] =     rmse(df_obs[\"Q [mm/day]\"], Q_sim) # calculate rmse for this paramter set \n",
    "\n",
    "    @interact(bias_threshold=(errors[:,0].min(), errors[:,0].max(), 0.005), rmse_threshold=(errors[:,1].min(), errors[:,1].max(), 0.005), zoom=(0, 0.5, 0.05), solution=False)\n",
    "    def plot_behavioral(bias_threshold=np.quantile(errors[:,0], 0.2), rmse_threshold=np.quantile(errors[:,1], 0.2), zoom=0, solution=False):\n",
    "        \n",
    "        # which paramters are behavioral\n",
    "        behavioral = (errors[:,0] <= bias_threshold) & (errors[:,1] <= rmse_threshold)\n",
    "        \n",
    "        # PLOT\n",
    "        fig, axs = plt.subplots(2, 5, figsize=(4*5, 4*2))\n",
    "\n",
    "        for i, metric in enumerate([\"|Bias|\", \"RMSE\"]):\n",
    "            \n",
    "            for j, param in enumerate([\"CWH\", \"BETA\", \"PERC\", \"UZL\"]):\n",
    "\n",
    "                # index of the paramter value\n",
    "                k = param_names.index(param)\n",
    "                \n",
    "                ax = axs[i, j]\n",
    "                if i == 0: ax.set_title(param)\n",
    "                ax.set_xlabel(param)\n",
    "                ax.set_ylabel(metric)\n",
    "                \n",
    "                # scatterplot for the metric values\n",
    "                ax.scatter(samples[:,k], errors[:,i], c=np.where(behavioral, \"blue\", \"red\"), alpha=0.75)\n",
    "\n",
    "                # rugplot of the behavioral paramters\n",
    "                ax.plot(samples[behavioral,k], errors[:,i].min() - 0.01 + np.zeros_like(samples[behavioral,k]), '|', color='blue', alpha=0.5) \n",
    "\n",
    "                # zoom into plot if set\n",
    "                ax.set_ylim([errors[:,i].min() - 0.02, ax.get_ylim()[1]*(1 - zoom)])\n",
    "\n",
    "                # horizontal line for the threshold\n",
    "                threshold = [bias_threshold, rmse_threshold][i]\n",
    "                if threshold < ax.get_ylim()[1]:\n",
    "                    ax.axhline(threshold, color=\"black\", ls=\"--\")\n",
    "                    label = ax.text(samples[:,k].min(), threshold, f\"{metric} = {threshold:.2f}\", ha=\"left\", va=\"center\", fontsize=10)\n",
    "                    label.set_bbox(dict(facecolor=\"white\"))\n",
    "            \n",
    "        ax = axs[0, -1]\n",
    "        cnts = np.unique(np.where(behavioral, \"Behavioral\", \"Non-Behavioral\"), return_counts=True)\n",
    "        bars = ax.bar(*cnts)\n",
    "        ax.set_ylim([0, ax.get_ylim()[1] + 10])\n",
    "        ax.set_title(\"Fraction of Behavioral Parameters\")\n",
    "        for i, (key, bar) in enumerate(zip(cnts[0], bars)):\n",
    "            bar.set_color(\"blue\" if key == \"Behavioral\" else \"red\")\n",
    "            ax.text(bar.xy[0] + bar.get_width()/2, bar.get_height(), f\"{bar.get_height()/N:.0%}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "        ax = axs[1, -1]\n",
    "        if solution:\n",
    "            ax.scatter(errors[:,0], errors[:,1], color=np.where(behavioral, \"blue\", \"red\"))\n",
    "            ax.set_xlabel(\"|Bias|\")\n",
    "            ax.set_ylabel(\"RMSE\")\n",
    "            ax.set_title(\"Bias - RMSE Scatterplot\")\n",
    "            ax.set_xlim([errors[:,0].min() - 0.02, ax.get_xlim()[1]*(1 - zoom)])\n",
    "            ax.set_ylim([errors[:,1].min() - 0.02, ax.get_ylim()[1]*(1 - zoom)])\n",
    "\n",
    "            if bias_threshold < ax.get_xlim()[1]:\n",
    "                ax.axvline(bias_threshold, color=\"black\", ls=\"--\")\n",
    "                label = ax.text(bias_threshold, np.mean(ax.get_ylim()), f\"|Bias| = {bias_threshold:.2f}\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "                label.set_bbox(dict(facecolor=\"white\"))\n",
    "            if rmse_threshold < ax.get_ylim()[1]:\n",
    "                ax.axhline(rmse_threshold, color=\"black\", ls=\"--\")\n",
    "                label = ax.text(np.mean(ax.get_xlim()), rmse_threshold, f\"RMSE = {rmse_threshold:.2f}\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "                label.set_bbox(dict(facecolor=\"white\"))\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06ca58-d625-49f7-a326-9d1c278e5f6d",
   "metadata": {
    "editable": true
   },
   "source": [
    "<div style=\"background:#e0f2fe;border:1mm solid SkyBlue; padding:1%\">\n",
    "    <h4><span>&#129300 </span>Task I: Thresholds</h4>\n",
    "    We have again run HBV for N different paramter combinations that come from a latin-hypercube strategy. In the scatterplots above you can see the absolute Bias and RMSE values for these runs. You can now select thresholds for the metrics. Once both metrics are below their threshold, a parameter set is marked as behavioral. On the bottom of the plot you see what is called a rugplot. Each tick indicates one behavioral parameter set. As you can see, we have omitted some parameters so that the plot is not too large.\n",
    "    <ol>\n",
    "        <li>How does changing the thresholds affect the distribution of behavioral parameters?</li>\n",
    "        <li>Why do you see some non-behavioral points that lie above the horizontal line that indices the threshold for a metric?</li>\n",
    "        <li>How do the thresholds look in a Bias-RMSE scatterplot? Where would you find the bahavioral parameters? Is there a better way to define a threshold?</li>\n",
    "    </ol>\n",
    "    You can show the solution to the third question by activating the solution checkbox.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f146f3-a8c3-4ee1-a9ad-dabb5afe632b",
   "metadata": {},
   "source": [
    "_PUT YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d170f91-5886-4f86-99a7-cb1a5468e0a0",
   "metadata": {},
   "source": [
    "<div style=\"background:#e0f2fe;border:1mm solid SkyBlue; padding:1%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0bfc73-d47a-4f0e-9e90-454e01650e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb45873a520456d9e4048e1e2bddb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.36870101321509546, description='bias_threshold', max=1.4772442719929…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(bias_threshold=(errors[:,0].min(), errors[:,0].max(), 0.005), rmse_threshold=(errors[:,1].min(), errors[:,1].max(), 0.005))\n",
    "def plot_behavioral(bias_threshold=np.quantile(errors[:,0], 0.2), rmse_threshold=np.quantile(errors[:,1], 0.2)):\n",
    "    \n",
    "    # which paramters are behavioral\n",
    "    behavioral = (errors[:,0] <= bias_threshold) & (errors[:,1] <= rmse_threshold)\n",
    "    \n",
    "    # PLOT\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(4*4, 4*1), sharex=\"col\", sharey=True)\n",
    "\n",
    "    for j, param in enumerate([\"CWH\", \"BETA\", \"PERC\", \"UZL\"]):\n",
    "\n",
    "        # index of the paramter value\n",
    "        k = param_names.index(param)\n",
    "        \n",
    "        ax = axs[j]\n",
    "        ax.set_xlabel(param)\n",
    "        ax.set_ylabel(\"Probability\")\n",
    "        ax.set_xlim(samples[:,k].min(), samples[:,k].max())\n",
    "        \n",
    "        # CDF plots\n",
    "        if behavioral.sum() > 1:\n",
    "            ax.ecdf(samples[ behavioral,k], color=\"blue\", label=\"Behavioral\")\n",
    "        if behavioral.sum() < len(behavioral):\n",
    "            ax.ecdf(samples[~behavioral,k], color=\"red\", label=\"Non-Behavioral\")\n",
    "\n",
    "        # uniform distribution\n",
    "        ax.plot(ax.get_xlim(), [0, 1], color=\"gray\", zorder=0, label=\"Uniform\")\n",
    "\n",
    "        # rugplot of the behavioral paramters\n",
    "        ax.plot(samples[ behavioral,k], 0.01 + np.zeros_like(samples[ behavioral,k]), '|', color='blue', alpha=0.5) \n",
    "        ax.plot(samples[~behavioral,k], 0.99 + np.zeros_like(samples[~behavioral,k]), '|', color='red',  alpha=0.5) \n",
    "\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae52b79-b43a-4037-bd5a-708af1111a80",
   "metadata": {
    "editable": true
   },
   "source": [
    "<div style=\"background:#e0f2fe;border:1mm solid SkyBlue; padding:1%\">\n",
    "    <h4><span>&#129300 </span>Task II: Cumulative Distribution Functions</h4>\n",
    "    Above you see the CDFs for the behavioral and non-behavioral parameter sets.\n",
    "    <ol>\n",
    "        <li>How does changing the thresholds affect the CDF of behavioral and non-behavioral parameters?</li>\n",
    "        <li>How can you read the values of well-performing parameter sets from the plot?</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b61c74-1523-4d82-a609-a9ce539ce3b9",
   "metadata": {},
   "source": [
    "_PUT YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e600a126-8557-4b41-88e3-0a94b78aae48",
   "metadata": {},
   "source": [
    "<div style=\"background:#e0f2fe;border:1mm solid SkyBlue; padding:1%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce3c5b-bf2d-4867-8dd6-d76b3f2c3038",
   "metadata": {},
   "source": [
    "## 4 GLUE Algorithm for Significance Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9aaf603-3568-4b48-a5c1-c5c5ae8d89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_percentile(data, weights, perc):\n",
    "    ix = np.argsort(data)\n",
    "    data = data[ix] # sort data\n",
    "    weights = weights[ix] # sort weights\n",
    "    cdf = (np.cumsum(weights) - 0.5 * weights) / np.sum(weights) # 'like' a CDF function\n",
    "    return np.interp(perc, cdf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f46f45-ed6f-4df0-a3e1-5860072224ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_sim_all = np.stack([hbv(sample, df_obs[\"P [mm/day]\"], df_obs[\"T [C]\"], df_obs[\"PET [mm/day]\"]) for sample in samples])\n",
    "# rerun this cell when you changed the number of paramter sets for the first task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c52112-bd4f-4685-8e50-c69fbb3eb111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06548191706c40a18a1f0ae6cf01bed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.36870101321509546, description='bias_threshold', max=1.4772442719929…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(bias_threshold=(errors[:,0].min(), errors[:,0].max(), 0.005), rmse_threshold=(errors[:,1].min(), errors[:,1].max(), 0.005))\n",
    "def plot_behavioral(bias_threshold=np.quantile(errors[:,0], 0.2), rmse_threshold=np.quantile(errors[:,1], 0.2)):\n",
    "\n",
    "    # only use behavioral samples\n",
    "    behavioral = (errors[:,0] <= bias_threshold) & (errors[:,1] <= rmse_threshold)\n",
    "    Q_sim = Q_sim_all[behavioral]\n",
    "    Q_obs = np.tile(df_obs[\"Q [mm/day]\"], (Q_sim.shape[0], 1))\n",
    "\n",
    "    # calculate likelihood of model run\n",
    "    likelihood = 1/np.var(Q_sim - Q_obs, axis=1)\n",
    "    \n",
    "    Q_sim_lower = np.apply_along_axis(lambda x: weighted_percentile(x, likelihood, 0.05), axis=0, arr=Q_sim)\n",
    "    Q_sim_upper = np.apply_along_axis(lambda x: weighted_percentile(x, likelihood, 0.95), axis=0, arr=Q_sim)\n",
    "    Q_sim_mean  = Q_sim.mean(axis=0)\n",
    "\n",
    "    # plot the GLUE approximation\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.fill_between(df_obs.Date, Q_sim_lower, Q_sim_upper, color=\"black\", alpha=0.2, label=\"90% CI\")\n",
    "    plt.plot(df_obs.Date, Q_sim_mean, color=\"black\", label=\"Ensemble Mean\")\n",
    "    plt.plot(df_obs.Date, Q_obs[0], color=\"red\", label=\"Observed\")\n",
    "    plt.xlim(df_obs.Date.iloc[4*365], df_obs.Date.iloc[5*365])\n",
    "    plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator())\n",
    "    plt.title(catchment_name)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Runoff [mm/day]\")\n",
    "    plt.legend()\n",
    "    \n",
    "    ax = plt.twinx()\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_ylabel(\"Precipitation [mm/day]\")\n",
    "    ax.bar(df_obs.Date, df_obs[\"P [mm/day]\"], color=\"C0\", label=\"Precipitation\", zorder=0)\n",
    "    ax.set_ylim([df_obs[\"P [mm/day]\"].max()*1.5, 0])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ba184-f253-4b10-8f38-a34480012124",
   "metadata": {
    "editable": true
   },
   "source": [
    "<div style=\"background:#e0f2fe;border:1mm solid SkyBlue; padding:1%\">\n",
    "    <h4><span>&#129300 </span>Task III: GLUE</h4>\n",
    "    In the above plot, you the a confidence interval estimate for the model runs using the GLUE method. It works by taking an average over the simualte runoff only for behavioral parameter sets. The likelihood for each parameter set is determined by how well the fit is.\n",
    "    <ol>\n",
    "        <li>How does the confidence interval change, when you alter the thresholds for absolute bias and RMSE?</li>\n",
    "        <li>Can you explain in your own words how the GLUE algorithm works?</li>\n",
    "    </ol>\n",
    "    As you can see, the fit between the GLUE ensemble and the observed runoff is quite poor. We suspect that this is due to problems in the HBV model.\n",
    "    <ol start=\"3\">\n",
    "        <li>Why could that be the case? Which misrepresentations of physical processes could lead to this mismatch between model results and observed runoff?</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524252b-d402-453d-bbd4-ba277d5a759f",
   "metadata": {},
   "source": [
    "_PUT YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346aad0d-2a6e-40d2-a6eb-208913ee15fc",
   "metadata": {},
   "source": [
    "<div style=\"background:#e0f2fe;border:1mm solid SkyBlue; padding:1%\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
