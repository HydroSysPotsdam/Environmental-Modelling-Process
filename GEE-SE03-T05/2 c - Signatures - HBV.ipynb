{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff46680b-1f14-4b25-bbf9-0b289b51b0bd",
   "metadata": {
    "editable": false
   },
   "source": [
    "![](./figures/Logo.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae7cf3-5f1c-4c4b-ac38-adaeb9ade587",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## In this part of the tutorial, you will\n",
    "* use several process-based signatures to assess model performance\n",
    "* learn how signatures provide diagnostic insights\n",
    "* add your own signature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655d4a5-96b8-46cc-b42c-a73d8c3df8a4",
   "metadata": {
    "editable": false
   },
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a063a-fe29-47bf-9d61-074dbb703840",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 2 c - Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc60b6-5224-4d3f-bae1-cd80feb13812",
   "metadata": {
    "editable": false
   },
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635da33-15d2-4cb4-aa0a-e08a456e14f7",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 1 About signatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "533c4832-c044-4805-b8c8-4584a57de6fa",
   "metadata": {
    "editable": false
   },
   "source": [
    "Statistical metrics quantify model fit, but it is often possible to achieve high metric values with an unrealistic model. Process-based signatures provide an alternative or complementary strategy for model evaluation with diagnostic potential. In the best case, signatures quantify underlying processes and therefore enable the modeller to compare how process dynamics are represented in the model in comparison to the real system. We can thus investigate where and when a model is an inadequate representation of the underlying system, and, equally important, how the model might be improved. [(Gupta et al., 2008)](https://doi.org/10.1002/hyp.6989        )\n",
    "\n",
    "In this tutorial, we use several signatures to analyse observed and modelled river discharge:\n",
    "* The **runoff ratio (RR)** is the proportion of precipitation that is not absorbed by the soil and vegetation, instead flowing over the land surface and into rivers or other water bodies.\n",
    "* The **baseflow index (BI)** is a measure of the proportion of streamflow in a river that originates from groundwater discharge, reflecting the contribution of baseflow to the overall streamflow.\n",
    "* The **recession constant** represents the rate at which a river's discharge decreases during the recession phase, characterizing the decline in streamflow following a peak flow event.\n",
    "* The **lag time** refers to the time delay between the occurrence of peak rainfall and the corresponding peak discharge in a river or watershed, reflecting the time taken for precipitation to reach and contribute to streamflow.\n",
    "* The **slope of the flow duration curve**, expressed as the negative of the derivative of exceedance probability with respect to flow, indicates the rate at which the probability of exceeding a given flow diminishes as discharge increases, providing insights into the streamflow variability across different percentiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97f84b-cf52-43c2-aa27-85c57a850c13",
   "metadata": {
    "editable": false
   },
   "source": [
    "<center>\n",
    "    <img src=\"./figures/signatures.png\" style=\"width:50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51043cc-01b0-4ba4-bc12-b127b0aab3a0",
   "metadata": {
    "editable": false
   },
   "source": [
    "<div style=\"background:#e0f2fe; padding: 1%; border:1mm solid SkyBlue; color:black\">\n",
    "    <h4><span>&#129300 </span>Task I: Signatures</h4>\n",
    "    In the last tutorial, you have learned about four different statistical metrics (Bias, RMSE, KGE, NSE) to evaluate model fit. As you have seen for yourself, model calibrations using different parameter sets can result in similar or even equal evaluation metrics. To overcome this problem and to constrain models to physically reasonable representations, we can additionally use signatures for model evaluation.\n",
    "    <ol>\n",
    "        <li>How do different signatures represent physical processes?</li>\n",
    "        <li>How are the signatures related to components of the evaluation metrics, such as the KGE?</li>\n",
    "        <li>How many signatures do we need to complement model evaluation and on what choices does this number depend?</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04cada6-da14-4ed1-b301-cf8b9bdad7f4",
   "metadata": {},
   "source": [
    "_PUT YOUR ANSWERS HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3005196-7a24-472f-bd2e-d9ab18481c08",
   "metadata": {
    "editable": false
   },
   "source": [
    "<div style=\"background:#e0f2fe; padding: 1%; border:1mm solid SkyBlue; color:black\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86315366-5a9a-4f89-ae6b-7ed2630f9ae5",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 2 Using hydrological signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f755f-e94e-4189-affe-e54114150c7d",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b214a76-ad32-4776-b819-4db5533d0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.special import boxcox1p\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "from matplotlib.lines import Line2D\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "import HBV\n",
    "from ipywidgets import interact, Dropdown, FloatSlider, Checkbox, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8918be-badd-4b1c-a6a4-4c1898b63d03",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Defining functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c9c342-78ed-4b50-811c-733b2cfd81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runoff_ratio(runoff, precip):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of mean runoff to mean precipitation.\n",
    "    \"\"\"\n",
    "    return round(np.divide(np.mean(runoff),np.mean(precip)), 3)\n",
    "\n",
    "\n",
    "def calc_percentile(data, x):  # used in \"slope_of_flow_duration_curve\"\n",
    "    \"\"\"\n",
    "    Find the x-th percentile value from the data based on flow duration curve.\n",
    "    \"\"\"\n",
    "    p = 1 - x/100 # transform to get exceedance probability\n",
    "    # get ranks as a proxy for exceedance probabilities\n",
    "    data_tmp = data[~np.isnan(data)] # remove NaN values\n",
    "    data_sorted = np.sort(data_tmp)\n",
    "    data_ranked = np.linspace(1,len(data_tmp),len(data_tmp)) # give unique (random) rank to every measurement\n",
    "    FDC = 1 - data_ranked / len(data_ranked) # flow duration curve\n",
    "    \n",
    "    # find x-th flow percentile\n",
    "    indices = np.linspace(1,len(FDC),len(FDC))\n",
    "    bound_x = int(np.max(indices[FDC >= p]))\n",
    "    data_x = data_sorted[bound_x]\n",
    "\n",
    "    return data_x\n",
    "\n",
    "\n",
    "def slope_of_flow_duration_curve(data):\n",
    "    \"\"\"\n",
    "    Calculate the difference between 33.3rd and 66.6th percentiles of the data.\n",
    "    \"\"\"\n",
    "    lower_percentile = 33.3 \n",
    "    upper_percentile = 66.6\n",
    "    return round(calc_percentile(data, lower_percentile) - calc_percentile(data, upper_percentile), 3)\n",
    "\n",
    "\n",
    "def baseflow_index(data):\n",
    "    \"\"\"\n",
    "    Compute the baseflow index as the mean of baseflow values.\n",
    "    \"\"\"\n",
    "    a = 0.925 # coefficient: https://www.scirp.org/(S(351jmbntvnsjt1aadkposzje))/journal/paperinformation.aspx?paperid=83002#return41\n",
    "    baseflow_t0 = 0\n",
    "    runoff_t0 = 0\n",
    "    l_baseflow = []\n",
    "    for i, runoff_t1 in enumerate(data):\n",
    "        if i > 0:\n",
    "            baseflow_t1 = (a * baseflow_t0) + (((1-a)/2) * (runoff_t1 + runoff_t0))  # compute baseflow: Q_b_t1 = a*Q_b_t0 + (1-a)/2) * (Q_t1 - Q_t0)\n",
    "            baseflow_t0 = baseflow_t1  # for next time step: migrate t1 to t0\n",
    "            l_baseflow.append(baseflow_t1)\n",
    "        runoff_t0 = runoff_t1  # for next time step: migrate t1 to t0\n",
    "    return round(np.mean(l_baseflow), 3)\n",
    "\n",
    "\n",
    "def find_peak_to_min(data):  # used in \"recession_constant\"\n",
    "    \"\"\"\n",
    "    Identify indices of peak value and the subsequent minimum in the data.\n",
    "    \"\"\"\n",
    "    id_max = np.argmax(data)  # get id of the max value in data\n",
    "    data_cropped = data[id_max:]  # crop data (cropped data starts with maximum)\n",
    "    # use argrelextrema to find local minima, use [0][0] to get the first one in cropped data\n",
    "    id_next_min = id_max + argrelextrema(data_cropped, np.less)[0][0] + 1\n",
    "    return id_max, id_next_min\n",
    "\n",
    "\n",
    "def recession_constant(data):\n",
    "    \"\"\"\n",
    "    Calculate the recession constant from peak to the next minimum in the data.\n",
    "    \"\"\"\n",
    "    id_peak, id_next_min = find_peak_to_min(data)\n",
    "    timesteps = id_next_min - id_peak\n",
    "    peak = data[id_peak]\n",
    "    next_min = data[id_next_min] # last element of data\n",
    "    return round(- np.log(peak/next_min)/ timesteps, 3)  # https://docs.niwa.co.nz/library/public/HHPP8.pdf\n",
    "\n",
    "\n",
    "def lag_time(data, data_obs, precip, search_range=100):\n",
    "    \"\"\"\n",
    "    Calculate the lag time between peak observed flow and prior peak precipitation.\n",
    "    \"\"\"\n",
    "    id_peak_flow_obs = np.argmax(data_obs)  # get id of peak observed flow\n",
    "    precip_cropped = precip[:id_peak_flow_obs+2]  # crop precip\n",
    "    id_prior_max_precip = argrelextrema(precip_cropped, np.greater)[0][-1]  # find id of local max precip before peak observed flow \n",
    "    # in line above: using [0] to get the first array, and [-1] to get last element of that array\n",
    "    data_cropped = data[id_peak_flow_obs-1:id_peak_flow_obs+search_range+2]  # crop data \n",
    "    # in line above: \n",
    "    #  - start slice at id_peak_flow_obs-1 to allow max to be found (needs the value before the max to determine it correctly)\n",
    "    #  - end slice at id_peak_flow_obs+search_range+2\n",
    "    id_data_cropped = argrelextrema(data_cropped, np.greater)[0][0] - 1 # get id of the first max value in cropped data\n",
    "    # in line above: using [0] to get the first array, and the next [0] to get the first element of that array\n",
    "    id_data = id_peak_flow_obs + id_data_cropped\n",
    "    return round(id_data - id_prior_max_precip, 3)\n",
    "\n",
    "def hbv(par, precip, temp, evap):\n",
    "    # Run HBV snow routine\n",
    "    p_s, _, _ = HBV.snow_routine(par[:4], temp, precip)\n",
    "    # Run HBV runoff simulation\n",
    "    Case = 1 # for now we assume that the preferred path in the upper zone is runoff (Case = 1), it can be set to percolation (Case = 2)\n",
    "    ini = np.array([0,0,0]) # initial state\n",
    "    runoff_sim, _, _ = HBV.hbv_sim(par[4:], p_s, evap, Case, ini)\n",
    "    return runoff_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b57d4-8893-49cc-bf0b-cb8257878bb1",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Create and display interactive menus for selecting catchment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1200784-27b1-4901-bafc-453f0a709536",
   "metadata": {
    "editable": false,
    "source_hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15456e97a1e4c19ba672edf4baf5b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Catchment:', options=('Medina River, TX, USA', 'Siletz River, OR, USA', 'Trout River, BC…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT ALTER! code to select the catchment\n",
    "\n",
    "catchment_names = [\"Medina River, TX, USA\", \"Siletz River, OR, USA\", \"Trout River, BC, Canada\"]\n",
    "dropdown = Dropdown(\n",
    "    options=catchment_names,\n",
    "    value=catchment_names[0],\n",
    "    description='Catchment:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d3738-d190-420a-9431-b117e0a5d4ee",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Read catchment data and prepare model input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a540ea-fb7e-4f60-88a4-741e10585cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read catchment data\n",
    "catchment_name = dropdown.value\n",
    "# Read catchment data\n",
    "file_dic = {catchment_names[0]: \"camels_08178880\", catchment_names[1]: \"camels_14305500\", catchment_names[2]: \"hysets_10BE007\"}\n",
    "df_obs = pd.read_csv(f\"data/{file_dic[catchment_name]}.csv\")\n",
    "# Make sure the date is interpreted as a datetime object -> makes temporal operations easier\n",
    "df_obs.date = pd.to_datetime(df_obs['date'], format='%Y-%m-%d')\n",
    "# Select time frame\n",
    "start_date = '2003-01-01'  # the first year is used as spin up. Evaluation is done for the time series after spin up.\n",
    "end_date = '2004-12-30'\n",
    "\n",
    "# Index frame by date\n",
    "df_obs.set_index('date', inplace=True)\n",
    "# Select time frame\n",
    "df_obs = df_obs[start_date:end_date]\n",
    "# Reformat the date for plotting\n",
    "df_obs[\"date\"] = df_obs.index.map(lambda s: s.strftime('%b-%d-%y'))\n",
    "# Reindex\n",
    "df_obs = df_obs.reset_index(drop=True)\n",
    "# Select snow, precip, PET, streamflow and T\n",
    "df_obs = df_obs[[\"snow_depth_water_equivalent_mean\", \"total_precipitation_sum\",\"potential_evaporation_sum\",\"streamflow\", \"temperature_2m_mean\", \"date\"]]\n",
    "# Rename variables\n",
    "df_obs.columns = [\"Snow [mm/day]\", \"P [mm/day]\", \"PET [mm/day]\", \"Q [mm/day]\", \"T [C]\", \"Date\"]\n",
    "\n",
    "# Prepare the data intput for both models\n",
    "P = df_obs[\"P [mm/day]\"].to_numpy()\n",
    "evap = df_obs[\"PET [mm/day]\"].to_numpy()\n",
    "temp = df_obs[\"T [C]\"].to_numpy()\n",
    "\n",
    "# load calibrated parameters\n",
    "params_calibrated = pd.read_csv(\"./data/calibrated_parameters - HBV.csv\")\n",
    "params_calibrated = params_calibrated[(params_calibrated.catchment_name == catchment_name) & (params_calibrated.objective_function == \"nse\")] # use only this catchment and the rmse parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafbfd4-a679-4250-bac8-65cf14926a1a",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Using signatures to evaluate HBV results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312ce915-3f88-4637-8696-8e8a0faa0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def your_own_signature(SWE):\n",
    "    \"\"\"SWE is the snow-water equivalent, i.e. the amount of water that is stored as snow in the catchment. \n",
    "       The function is once called with the measured SWE and once with the simulated SWE.\"\"\"\n",
    "    # TODO: implement your own idea here\n",
    "    return \"implement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c036cea7-4a5a-4964-8478-312c21ec61ae",
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e0ec358037420f95b2ba03ddf3e972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='Log Scale for Flow Curve'), FloatSlider(value=1.0, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT ALTER! code to calculate and plot the signatures\n",
    "\n",
    "param_names = [\"Ts\", \"CFMAX\", \"CFR\", \"CWH\", \"BETA\", \"LP\", \"FC\", \"PERC\", \"K0\", \"K1\", \"K2\", \"UZL\", \"MAXBAS\"]\n",
    "lower       = [-3, 0, 0, 0, 0, 0.3, 1, 0, 0.05, 0.01, 0.005, 0, 1] # lower bounds for the parameters\n",
    "upper       = [3, 20, 1, 0.8, 7, 1, 2000, 100, 2, 1, 0.1, 100, 6]  # upper bounds for the parameters\n",
    "\n",
    "# widgets for easy input\n",
    "params = {param: FloatSlider(value=params_calibrated.round(1).iloc[0, j+3], min=xmin, max=xmax, step=0.1, description=param) for j, xmin, xmax, param in zip(range(13), lower, upper, param_names)}\n",
    "\n",
    "@interact(scalelog=Checkbox(value=False, description=\"Log Scale for Flow Curve\"), lmbda=FloatSlider(min=-2, max=2, step=0.1, value=1, description=\"BC Lambda\"), sep=HTML(\"HBV Parameters ---\", description=\"---\"), **params)\n",
    "def signature_function(scalelog, lmbda=0, sep=\"\", **params):\n",
    "    \n",
    "    # run HBV simulation\n",
    "    params = np.array(list(params.values()))\n",
    "    Q_sim = hbv(params, P, temp, evap)\n",
    "    Q_obs = df_obs[\"Q [mm/day]\"].values\n",
    "\n",
    "    # run snow component for HBV\n",
    "    _, SWE_sim, _ = HBV.snow_routine(params[:4], temp, P)\n",
    "    SWE_sim = SWE_sim[:,0] + SWE_sim[:,1]\n",
    "\n",
    "    signatures = [\"Runoff Ratio\", \"Central Slope\", \"Baseflow Index\", \"Fast Recession Constant\", \"Lag Time\", \"Your Snow Signature\"]  \n",
    "    results_sim = [runoff_ratio(Q_sim, P), slope_of_flow_duration_curve(Q_sim), baseflow_index(Q_sim), recession_constant(Q_sim), lag_time(Q_sim, Q_obs, P), your_own_signature(SWE_sim)]\n",
    "    results_obs = [runoff_ratio(Q_obs, P), slope_of_flow_duration_curve(Q_obs), baseflow_index(Q_obs), recession_constant(Q_obs), lag_time(Q_obs, Q_obs, P), your_own_signature(df_obs[\"Snow [mm/day]\"])]\n",
    "    df_results = pd.DataFrame({\"Observed\": results_obs, \"Simulated\": results_sim}, index=signatures)\n",
    "    \n",
    "    # --- PLOTS ---\n",
    "    \n",
    "    plt.figure(figsize=(25, 5))\n",
    "\n",
    "    # OBSERVED AND SIMULATED RUNOFF (using BoxCox)\n",
    "    plt.subplot(131)\n",
    "    plt.title(f\"Hydrograph (with BC Lambda = {lmbda:.1f})\")\n",
    "    lineobs, = plt.plot(df_obs[\"Date\"], boxcox1p(Q_obs, lmbda), color=\"black\")\n",
    "    linesim, = plt.plot(df_obs[\"Date\"], boxcox1p(Q_sim, lmbda), color=\"C3\")\n",
    "    plt.gca().xaxis.set_major_locator(mdate.MonthLocator(interval=2))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Q [mm/day]\")\n",
    "    \n",
    "    # PRECIPITATION \n",
    "    ax = plt.twinx()\n",
    "    ax.invert_yaxis()\n",
    "    pbar = ax.bar(df_obs[\"Date\"], df_obs[\"P [mm/day]\"], color=\"skyblue\")\n",
    "    ax.set_ylabel(\"P [mm/day]\")\n",
    "    plt.legend([lineobs, linesim, pbar], [\"Observed\", \"Simulated\", \"Precipitation\"], loc=\"upper left\")\n",
    "\n",
    "    # FLOW DURATION CURVES \n",
    "    plt.subplot(132)\n",
    "    sns.ecdfplot(y=Q_obs, color=\"black\", complementary=True, ax=plt.gca(), label=\"Observed\")\n",
    "    sns.ecdfplot(y=Q_sim, color=\"red\",   complementary=True, ax=plt.gca(), label=\"Simulated\")\n",
    "    plt.title(\"Flow Duration Curve\")\n",
    "    plt.ylabel(\"Q [mm/day]\")\n",
    "    plt.legend()\n",
    "    if scalelog:\n",
    "        plt.loglog()\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(df_obs[\"Date\"], df_obs[\"Snow [mm/day]\"], color=\"black\", label=\"Observed\")\n",
    "    plt.plot(df_obs[\"Date\"], SWE_sim[1:], color=\"red\", label=\"Simulated\")\n",
    "    plt.title(\"Snow Water-Equivalent\")\n",
    "    plt.gca().xaxis.set_major_locator(mdate.MonthLocator(interval=2))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"SWE [mm]\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.gcf().suptitle(catchment_name, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # display signatures\n",
    "    display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ecce1-ef88-450f-85c1-64661ad5b503",
   "metadata": {
    "editable": false
   },
   "source": [
    "<div style=\"background:#e0f2fe; padding: 1%; border:1mm solid SkyBlue; color:black\">\n",
    "    <h4><span>&#129300 </span>Your Turn II: Applying Signatures to HBV</h4>\n",
    "    Above you will find the simulated and observed hydrographs for the catchment that you selected (remember to rerurn the code when you change this). The right plot shots the flow duration curve, i.e. the cumulative distribution function (CDF) of the observed and simulated runoff. You can again transform the data in the hydrograph using the Box-Cox transformation with the lambda parameter and enable logarithmic scaling in the CDF.\n",
    "    <ol>\n",
    "        <li>Which processes in the HBV model are linked to which signatures? Which parameters affect certain signatures?</li>\n",
    "    </ol>\n",
    "    Please change the catchment to Trout or Siletz River. Above the plot, you will find an empty function. It will be called once with the observed snow water-equivalent, i.e. the amount of water stored in the snowpack, and once with the simulated data.\n",
    "    <ol start=\"2\">\n",
    "        <li>What could you use as a snow-related signature?</li>\n",
    "        <li>Can you implement this signature?</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af6ac5-4e96-466e-8864-1ffbd8dde44b",
   "metadata": {},
   "source": [
    "_PUT YOUR ANSWERS HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9713b5d-3ee7-49aa-92d9-6330f234c1c8",
   "metadata": {
    "editable": false
   },
   "source": [
    "<div style=\"background:#e0f2fe; padding: 1%; border:1mm solid SkyBlue; color:black\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
