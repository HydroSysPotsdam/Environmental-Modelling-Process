{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff46680b-1f14-4b25-bbf9-0b289b51b0bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "![](./figures/Logo.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae7cf3-5f1c-4c4b-ac38-adaeb9ade587",
   "metadata": {
    "editable": true
   },
   "source": [
    "## In this part of the tutorial, you will\n",
    "* use several process-based signatures to assess model performance\n",
    "* learn how signatures provide diagnostic insights\n",
    "* add your own signature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655d4a5-96b8-46cc-b42c-a73d8c3df8a4",
   "metadata": {
    "editable": true
   },
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a063a-fe29-47bf-9d61-074dbb703840",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 2 c - Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc60b6-5224-4d3f-bae1-cd80feb13812",
   "metadata": {
    "editable": true
   },
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635da33-15d2-4cb4-aa0a-e08a456e14f7",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1 About signatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "533c4832-c044-4805-b8c8-4584a57de6fa",
   "metadata": {
    "editable": true
   },
   "source": [
    "Statistical metrics quantify model fit, but it is often possible to achieve high metric values with an unrealistic model. Process-based signatures provide an alternative or complementary strategy for model evaluation with diagnostic potential. In the best case, signatures quantify underlying processes and therefore enable the modeller to compare how process dynamics are represented in the model in comparison to the real system. We can thus investigate where and when a model is an inadequate representation of the underlying system, and, equally important, how the model might be improved. [(Gupta et al., 2008)](https://doi.org/10.1002/hyp.6989        )\n",
    "\n",
    "In this tutorial, we use several signatures to analyse observed and modelled river discharge:\n",
    "* The **runoff ratio** is the proportion of precipitation that is not absorbed by the soil and vegetation, instead flowing over the land surface and into rivers or other water bodies.\n",
    "* The **slope of the flow duration curve**, expressed as the negative of the derivative of exceedance probability with respect to flow, indicates the rate at which the probability of exceeding a given flow diminishes as discharge increases, providing insights into the streamflow variability across different percentiles.\n",
    "* The **baseflow index** is a measure of the proportion of streamflow in a river that originates from groundwater discharge, reflecting the contribution of baseflow to the overall streamflow.\n",
    "* The **recession constant** represents the rate at which a river's discharge decreases during the recession phase, characterizing the decline in streamflow following a peak flow event.\n",
    "* The **lag time** refers to the time delay between the occurrence of peak rainfall and the corresponding peak discharge in a river or watershed, reflecting the time taken for precipitation to reach and contribute to streamflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51043cc-01b0-4ba4-bc12-b127b0aab3a0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<div style=\"background:#e0f2fe; padding: 1%; border:1mm solid SkyBlue; color:black\">\n",
    "    <h4><span>&#129300 </span>Task I I: Signatures</h4>\n",
    "    In the last tutorial, you have learned about four different statistical metrics (Bias, RMSE, KGE, NSE) to evaluate model fit. As you have seen for yourself, model calibrations using different parameter sets can result in similar or even equal evaluation metrics. To overcome this problem and to constrain models to physically plausible representations, we can additionally use signatures for model evaluation.\n",
    "    <ol>\n",
    "        <li>How are signatures and the NSE/KGE components (bias, variability, correlation) related?</li>\n",
    "        <li>In how far are the NSE/KGE components diagnostic?</li>\n",
    "        <li>Discuss with your neighbour: How many signatures do we actually need for a modelling study? What does the number depend on?</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86315366-5a9a-4f89-ae6b-7ed2630f9ae5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2 Using hydrological signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f755f-e94e-4189-affe-e54114150c7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b214a76-ad32-4776-b819-4db5533d0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "from matplotlib.lines import Line2D\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "import HyMod\n",
    "from ipywidgets import interact, Dropdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8918be-badd-4b1c-a6a4-4c1898b63d03",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Defining functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c9c342-78ed-4b50-811c-733b2cfd81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runoff_ratio(runoff, precip):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of mean runoff to mean precipitation.\n",
    "    \"\"\"\n",
    "    return round(np.divide(np.mean(runoff),np.mean(precip)), 3)\n",
    "\n",
    "\n",
    "def calc_percentile(data, x):  # used in \"slope_of_flow_duration_curve\"\n",
    "    \"\"\"\n",
    "    Find the x-th percentile value from the data based on flow duration curve.\n",
    "    \"\"\"\n",
    "    p = 1 - x/100 # transform to get exceedance probability\n",
    "    # get ranks as a proxy for exceedance probabilities\n",
    "    data_tmp = data[~np.isnan(data)] # remove NaN values\n",
    "    data_sorted = np.sort(data_tmp)\n",
    "    data_ranked = np.linspace(1,len(data_tmp),len(data_tmp)) # give unique (random) rank to every measurement\n",
    "    FDC = 1 - data_ranked / len(data_ranked) # flow duration curve\n",
    "    \n",
    "    # find x-th flow percentile\n",
    "    indices = np.linspace(1,len(FDC),len(FDC))\n",
    "    bound_x = int(np.max(indices[FDC >= p]))\n",
    "    data_x = data_sorted[bound_x]\n",
    "\n",
    "    return data_x\n",
    "\n",
    "\n",
    "def slope_of_flow_duration_curve(data):\n",
    "    \"\"\"\n",
    "    Calculate the difference between 33.3rd and 66.6th percentiles of the data.\n",
    "    \"\"\"\n",
    "    lower_percentile = 33.3 \n",
    "    upper_percentile = 66.6\n",
    "    return round(calc_percentile(data, lower_percentile) - calc_percentile(data, upper_percentile), 3)\n",
    "\n",
    "\n",
    "def baseflow_index(data):\n",
    "    \"\"\"\n",
    "    Compute the baseflow index as the mean of baseflow values.\n",
    "    \"\"\"\n",
    "    a = 0.925 # coefficient: https://www.scirp.org/(S(351jmbntvnsjt1aadkposzje))/journal/paperinformation.aspx?paperid=83002#return41\n",
    "    baseflow_t0 = 0\n",
    "    runoff_t0 = 0\n",
    "    l_baseflow = []\n",
    "    for i, runoff_t1 in enumerate(data):\n",
    "        if i > 0:\n",
    "            baseflow_t1 = (a * baseflow_t0) + (((1-a)/2) * (runoff_t1 + runoff_t0))  # compute baseflow: Q_b_t1 = a*Q_b_t0 + (1-a)/2) * (Q_t1 - Q_t0)\n",
    "            baseflow_t0 = baseflow_t1  # for next time step: migrate t1 to t0\n",
    "            l_baseflow.append(baseflow_t1)\n",
    "        runoff_t0 = runoff_t1  # for next time step: migrate t1 to t0\n",
    "    return round(np.mean(l_baseflow), 3)\n",
    "\n",
    "\n",
    "def find_peak_to_min(data):  # used in \"recession_constant\"\n",
    "    \"\"\"\n",
    "    Identify indices of peak value and the subsequent minimum in the data.\n",
    "    \"\"\"\n",
    "    id_max = np.argmax(data)  # get id of the max value in data\n",
    "    data_cropped = data[id_max:]  # crop data (cropped data starts with maximum)\n",
    "    # use argrelextrema to find local minima, use [0][0] to get the first one in cropped data\n",
    "    id_next_min = id_max + argrelextrema(data_cropped, np.less)[0][0] + 1\n",
    "    return id_max, id_next_min\n",
    "\n",
    "\n",
    "def recession_constant(data):\n",
    "    \"\"\"\n",
    "    Calculate the recession constant from peak to the next minimum in the data.\n",
    "    \"\"\"\n",
    "    id_peak, id_next_min = find_peak_to_min(data)\n",
    "    timesteps = id_next_min - id_peak\n",
    "    peak = data[id_peak]\n",
    "    next_min = data[id_next_min] # last element of data\n",
    "    return round(- np.log(peak/next_min)/ timesteps, 3)  # https://docs.niwa.co.nz/library/public/HHPP8.pdf\n",
    "\n",
    "\n",
    "def lag_time(data, data_obs, precip, search_range=100):\n",
    "    \"\"\"\n",
    "    Calculate the lag time between peak observed flow and prior peak precipitation.\n",
    "    \"\"\"\n",
    "    id_peak_flow_obs = np.argmax(data_obs)  # get id of peak observed flow\n",
    "    precip_cropped = precip[:id_peak_flow_obs+2]  # crop precip\n",
    "    id_prior_max_precip = argrelextrema(precip_cropped, np.greater)[0][-1]  # find id of local max precip before peak observed flow \n",
    "    # in line above: using [0] to get the first array, and [-1] to get last element of that array\n",
    "    data_cropped = data[id_peak_flow_obs-1:id_peak_flow_obs+search_range+2]  # crop data \n",
    "    # in line above: \n",
    "    #  - start slice at id_peak_flow_obs-1 to allow max to be found (needs the value before the max to determine it correctly)\n",
    "    #  - end slice at id_peak_flow_obs+search_range+2\n",
    "    id_data_cropped = argrelextrema(data_cropped, np.greater)[0][0] - 1 # get id of the first max value in cropped data\n",
    "    # in line above: using [0] to get the first array, and the next [0] to get the first element of that array\n",
    "    id_data = id_peak_flow_obs + id_data_cropped\n",
    "    return round(id_data - id_prior_max_precip, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b57d4-8893-49cc-bf0b-cb8257878bb1",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Create and display interactive menus for selecting catchment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1200784-27b1-4901-bafc-453f0a709536",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": false
    },
    "source_hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74f2e4ede8d4c94845ce7617bad7dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Catchment:', options=('Medina River, TX, USA', 'Siletz River, OR, USA', 'Trout River, BC…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT ALTER! code to select the catchment\n",
    "\n",
    "catchment_names = [\"Medina River, TX, USA\", \"Siletz River, OR, USA\", \"Trout River, BC, Canada\"]\n",
    "dropdown = Dropdown(\n",
    "    options=catchment_names,\n",
    "    value=catchment_names[0],\n",
    "    description='Catchment:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d3738-d190-420a-9431-b117e0a5d4ee",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Read catchment data and prepare model input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a540ea-fb7e-4f60-88a4-741e10585cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read catchment data\n",
    "catchment_name = dropdown.value\n",
    "# Read catchment data\n",
    "file_dic = {catchment_names[0]: \"camels_08178880\", catchment_names[1]: \"camels_14305500\", catchment_names[2]: \"hysets_10BE007\"}\n",
    "df_obs = pd.read_csv(f\"data/{file_dic[catchment_name]}.csv\")\n",
    "# Make sure the date is interpreted as a datetime object -> makes temporal operations easier\n",
    "df_obs.date = pd.to_datetime(df_obs['date'], format='%Y-%m-%d')\n",
    "# Select time frame\n",
    "start_date = '2003-01-01'  # the first year is used as spin up. Evaluation is done for the time series after spin up.\n",
    "end_date = '2004-12-30'\n",
    "\n",
    "# Index frame by date\n",
    "df_obs.set_index('date', inplace=True)\n",
    "# Select time frame\n",
    "df_obs = df_obs[start_date:end_date]\n",
    "# Reformat the date for plotting\n",
    "df_obs[\"date\"] = df_obs.index.map(lambda s: s.strftime('%b-%d-%y'))\n",
    "# Reindex\n",
    "df_obs = df_obs.reset_index(drop=True)\n",
    "# Select snow, precip, PET, streamflow and T\n",
    "df_obs = df_obs[[\"snow_depth_water_equivalent_mean\", \"total_precipitation_sum\",\"potential_evaporation_sum\",\"streamflow\", \"temperature_2m_mean\", \"date\"]]\n",
    "# Rename variables\n",
    "df_obs.columns = [\"Snow [mm/day]\", \"P [mm/day]\", \"PET [mm/day]\", \"Q [mm/day]\", \"T [C]\", \"Date\"]\n",
    "\n",
    "# Prepare the data intput for both models\n",
    "P = df_obs[\"P [mm/day]\"].to_numpy()\n",
    "evap = df_obs[\"PET [mm/day]\"].to_numpy()\n",
    "temp = df_obs[\"T [C]\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafbfd4-a679-4250-bac8-65cf14926a1a",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Using signatures to evaluate HyMOD results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f791fc5-a137-49f5-8c2a-ef095ffa97bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dccb1e985674f5d9e7f7a7ac2c0ae17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=200, description='Sm', max=400), FloatSlider(value=0.32, description='be…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(\n",
    "    Sm = (0, 400, 1), beta = (0, 2, 0.01), alpha = (0, 1, 0.01), Rs=(8.0, 200.0, 0.5), Rf=(1.0, 7.0, 0.1)\n",
    ").options(manual=True, manual_name=\"Run Simulation...\")    \n",
    "def signature_function(Sm=200, beta=0.32, alpha=0.45, Rs=150, Rf=2.6):\n",
    "    # Calculate signatures\n",
    "    signatures = [\"Runoff ratio\", \"Central slope\", \"Baseflow index\", \"Fast recession constant\", \"Lag time\"]  \n",
    "    param = np.array([Sm, beta, alpha, 1/Rs, 1/Rf])\n",
    "    sim, states, fluxes = HyMod.hymod_sim(param, P, evap)  # Run HyMOD simulation\n",
    "    df_model = pd.DataFrame({'Q [mm/day]': sim, 'ET [mm/day]': fluxes.T[0], 'Date': df_obs[\"Date\"].to_numpy()})\n",
    "    df_model_eval = df_model.iloc[365:]\n",
    "    sim = df_model_eval[\"Q [mm/day]\"].values\n",
    "    df_obs_eval = df_obs.iloc[365:]\n",
    "    obs = df_obs_eval[\"Q [mm/day]\"].values\n",
    "    results_sim = [runoff_ratio(sim, P), slope_of_flow_duration_curve(sim), baseflow_index(sim), recession_constant(sim), lag_time(sim, obs, P)]\n",
    "    results_obs = [runoff_ratio(obs, P), slope_of_flow_duration_curve(obs), baseflow_index(obs), recession_constant(obs), lag_time(obs, obs, P)]\n",
    "    df_results = pd.DataFrame({\"Signature\": signatures, \"Observed\": results_obs, \"Simulated\": results_sim})\n",
    "    \n",
    "    # Plot results\n",
    "    plt.close()\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 3))\n",
    "    fig.suptitle(catchment_name)  # set figure title\n",
    "    # Plot the simulated and observed Q\n",
    "    sns.lineplot(data=df_model_eval, x=\"Date\", y=\"Q [mm/day]\", color=\"red\", ax=axes[0])\n",
    "    sns.lineplot(data=df_obs_eval, x=\"Date\", y=\"Q [mm/day]\", color=\"black\", ax=axes[0])\n",
    "    # Get the right hand side second y-axis and plot the precipitation as inverted bars\n",
    "    a1 = axes[0].twinx()\n",
    "    sns.barplot(data=df_obs_eval, x=\"Date\", y=\"P [mm/day]\", ax=a1, label=\"P\", color=\"dodgerblue\", alpha=0.5)\n",
    "    a1.invert_yaxis()\n",
    "    # Show only the main ticks\n",
    "    locator = mdate.MonthLocator()\n",
    "    plt.gca().xaxis.set_major_locator(locator) \n",
    "    axes[0].tick_params(axis='x', labelrotation=45)\n",
    "    # Add custom legend\n",
    "    custom_lines = [Line2D([0], [0], color=\"black\", lw=2), Line2D([0], [0], color=\"red\", lw=2), \n",
    "                    Line2D([0], [0], color=\"dodgerblue\", lw=2)]\n",
    "    axes[0].legend(custom_lines, ['Observed discharge','Simulated discharge','Precipitation (P)'], \n",
    "                   bbox_to_anchor=(0, 1, 1, 0), loc=\"lower left\")\n",
    "    # Set subplot title\n",
    "    axes[0].set_title(\"Hydrograph\")\n",
    "    # Plot the flow duration curves\n",
    "    sns.ecdfplot(df_model_eval, y=\"Q [mm/day]\", complementary=True, ax=axes[1], color=\"red\")\n",
    "    sns.ecdfplot(df_obs_eval, y=\"Q [mm/day]\", complementary=True, ax=axes[1], color=\"black\")\n",
    "    axes[1].set_title(\"Flow duration curve\")\n",
    "    axes[1].set_xlabel(\"Exceedance probability\")\n",
    "    \n",
    "    plt.show()  # Display the figure\n",
    "    print(df_results)  # Print results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa784c4-e401-4d3d-8a29-1ebbdcc7407b",
   "metadata": {
    "editable": true
   },
   "source": [
    "**NOTE:** It now takes a bit longer than in the last tutorials to run the HyMod and calculate signatures. Therefore, the interactive plot does not update any time you move the slider. Please click _Run Simulation..._ after you changed parameters to see the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ecce1-ef88-450f-85c1-64661ad5b503",
   "metadata": {
    "editable": true
   },
   "source": [
    "<div style=\"background:#e0f2fe; padding: 1%; border: 1mm solid SkyBlue\">\n",
    "    <h4><span>&#129300 </span>Your Turn II: Applying Signatures to HyMod</h4>\n",
    "    <ol>\n",
    "        <li>How do you think the applied signatures link to the processes (and thus parameters) included in HyMod (see figure below)?</li>\n",
    "        <li>Can you implement an additional signature for very dry and for snow-driven systems (see pictures below)?</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc1a96-078a-4dcb-8722-9a4d0a24a991",
   "metadata": {
    "editable": true
   },
   "source": [
    "![](./figures/Hymod_fig_cropped.PNG)\n",
    "![https://commons.wikimedia.org/wiki/File:NachalParan1.jpg, https://commons.wikimedia.org/wiki/File:Snow_Melts_into_River_near_Iceberg_Lake_in_Glacier_National_Park.jpg](./figures/dry_snow_river.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
